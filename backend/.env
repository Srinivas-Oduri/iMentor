# Ollama Configuration
# Ensure the Ollama server is running and accessible at this URL.




OLLAMA_BASE_URL="http://127.0.0.1:11434"


# --- Choose your LLMs ---
# Make sure the models specified here have been pulled using `ollama pull <model_name>`

# Generation/Analysis Model (Used for chat responses, analysis tasks)
# Recommended: deepseek-coder:6.7b-instruct (Good balance of coding/reasoning)
# Alternative: deepseek-r1 (If provided)
# Alternative: llama3:8b (Strong general model)
# Alternative: mistral:7b (Good general model)
#OLLAMA_MODEL=deepseek-r1
# OLLAMA_MODEL=llama3:8b
# OLLAMA_MODEL=llama3.2
#OLLAMA_MODEL=mistral:7b-instruct
OLLAMA_MODEL="llama3.1:latest"
# OLLAMA_MODEL="qwen2.5:14b-instruct" # Recommended for coding tasks
# Embedding Model (Used for creating vector representations of text)
# Recommended: mxbai-embed-large (Top performer on MTEB leaderboard)
# Alternative: nomic-embed-text (Another good option)
OLLAMA_EMBED_MODEL="mxbai-embed-large"
# OLLAMA_EMBED_MODEL=nomic-embed-text

# Optional: Ollama Request Timeout (seconds)
# Increase if you get timeout errors during long embedding or generation tasks
# OLLAMA_REQUEST_TIMEOUT=180

# --- Application Configuration ---
# Paths are relative to the 'backend' directory. Defaults are usually fine.
# FAISS_FOLDER=faiss_store
# UPLOAD_FOLDER=uploads
# DATABASE_NAME=chat_history.db
# DEFAULT_PDFS_FOLDER=default_pdfs

# --- RAG Configuration ---
# RAG_CHUNK_K=5               # Max unique chunks sent to LLM for synthesis
# RAG_SEARCH_K_PER_QUERY=3    # Chunks retrieved per sub-query before deduplication
# MULTI_QUERY_COUNT=3         # Number of sub-queries generated (0 to disable)

# --- Analysis Configuration ---
# ANALYSIS_MAX_CONTEXT_LENGTH=8000 # Max characters of document text sent for analysis

# --- Logging Configuration ---
# Level: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Set to DEBUG for detailed troubleshooting.
LOGGING_LEVEL=INFO
# LOGGING_LEVEL=DEBUG
WHISPER_MODEL="base"

JWT_SECRET="39031e2128181ce6e943b969d80e13e0e25a14026971b6340499174312374c5422e4282158c5c7a795fae95dc80a479f9ed3375bcbe55a80a815b18915024da17e27100d455a2d23beb36ffcd5d6e20f9c80cf92ffb76307c2bc57c2132c18d806b0c7b51f66fdb5d46ec7c7538c9379a2e6dea28af7b8c552d0d76fac545714d72845eb130be8fe229bae9c9c6891849c6f4e14b3e36ac3f2106f1e5ac0491d5a63c5bcd63cec5f394f39fdb45d4e61cb8c2e24339b926cb7303d43a31572128767e1247849dedba579e8ce1415488d5ffefba5a970b88b5383c6a305fdbbcf384eb6bf54c7ec6d4ff8d6abc3537bf5234be51657e0a55979032ae8e2cfcc0c"
MONGO_URI="mongodb+srv://srinivasoduri5:12345abc56@cluster56.psloa8d.mongodb.net/notebook_llm_ollama_db?retryWrites=true&w=majority"


FLASK_SECRET_KEY="9e384a455ac23031f2bebef264cb7af525cdd65e1d37154acaa58a14ff9668db"
GOOGLE_CLIENT_ID="43586474795-0cnre0cfmhibmcgabuj20qagira7ld46.apps.googleusercontent.com"
GOOGLE_CLIENT_SECRET="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"

GEMINI_API_KEY=AIzaSyAubQMTEw8AbP85FpXET7NY8ZvSEOyj9vI

# For Gemini 1.5 Pro (recommended)
# GEMINI_API_URL=https://generativelanguage.googleapis.com/v1/models/gemini-1.5-pro-latest:generateContent

# For Gemini 1.5 Flash (faster, cheaper)
GEMINI_API_URL=https://generativelanguage.googleapis.com/v1/models/gemini-1.5-flash:generateContent

# For Gemini Pro (older, but still supported)
# GEMINI_API_URL=https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent

# For Gemini 2.5 Pro (latest)
# GEMINI_API_URL=https://generativelanguage.googleapis.com/v1/models/gemini-2.5-pro-preview-03-25:generateContent

SEARCH_API_KEY = "" # https://console.cloud.google.com/apis/credentials
SEARCH_ENGINE_ID = "" # https://programmablesearchengine.google.com/